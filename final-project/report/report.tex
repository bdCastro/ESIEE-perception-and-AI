\documentclass[conference]{IEEEtran}
\usepackage{graphicx} % Required for inserting images

\title{TP3 Report - Perception and AI}
\author{\IEEEauthorblockN{Bruno Luiz Dias Alves de Castro}
\IEEEauthorblockA{\textit{ESIEE Paris}}
\and
\IEEEauthorblockN{Victor Gabriel Mendes SÃ¼ndermann}
\IEEEauthorblockA{\textit{ESIEE Paris}}
}
\date{February 2024}

\begin{document}

\maketitle

\section{Introduction}

Object counting is a process in Computer Vision where, as the name implies, aims to count how many instances of a certain object appear in an image. This process can be used in various areas and can bring about great advantages, such as: resource optimization, improved security, informed decision making, and other.

This can be done in more traditional ways, using state-of-the-art image segmentation methods, such as threshold or watershed, or by more complex and advanced methods like Artificial Intelligence and Neural Networks.

With the decrease in cost of hardware and Artificial Intelligence becoming more widespread, it is necessary to embrace this new technology and find ways use it in common contexts. Jetson Nano is platform designed by NVIDIA that can run multiple parallel neural networks with different applications, this micro computer aims to be the main platform for development of Neural Network applications.
\subsection{Objectives}

The objectives from this practical work are simple and straight forward: develop a network capable of properly recognizing pedestrian in a video footage, using two types of data: a regular video stream, and an infrared footage.

The network developed must be deployed and tested in two circumstances: with and without GPU, and with such evaluate the possibility of deploying out network in a real world scenario.

\section{Data preparation}

The first step in our development, was preparing the data we had for training and validation. For this, we were provided with frames from real video footage captured in a car. Our task was to select a few of these frames that contain pedestrians in them, and highlight them, using a rectangle. There are multiple ways this task could have been done, but we chose a software called \textit{\textbf{Roboflow}}.

\subsection{Roboflow}

\textit{\textbf{Roboflow}} is a web framework focused on data preparation and dataset development. It provides us with all the tools needed for classifying and prepossess our images. It also provides us easy methods of deployment, such as an API, to better import our datasets into our projects without the need to juggle files around.

The dataset prepared with \textit{\textbf{Robolow}} was imported into a \textit{\textbf{Python Notebook}}, and the project development followed, using \textit{\textbf{Google Colab}}.

\section{Development}

Among all the technologies used during this project, a few can be highlighted:

\begin{itemize}
    \item \textit{\textbf{Ultralytics}}: a library that helps us retrieving data such as performance and specifications from our CPU.
    \item \textit{\textbf{YOLO}}: a real-time object detection system from \textit{\textbf{Ultralytics}}, trained in our project.
    \item \textit{\textbf{OpenCV}}: a optimized Computer Vision library that provides tools and hardware.
\end{itemize}

We decided to use YOLO as the detection network because it is a state of the art system, being both fast and accurate when compared to other famous systems, like RetinaNet or SSD.

An essential part in this work is data preparation, in order for the network to be as effective as possible we created a database comprised of 168 annotated images. We applied various augmentation methods in the images to further train our network, resulting in a total of 436 images divided as 92\% training and 8\% validation.

The training of our network was done in 25 epochs and using two different hardware. First we ran the program on the CPU, and later we focused on the use of the GPU. The learning rates and the detection results are laid out in the following subsections.

\subsection{CPU Implementation}
The CPU execution unfortunately didn't bring any satisfactory results, likely because the network was trained in such a small number of epochs, and most likely didn't get to learn how to detect people. It is also important to note that the training took 18.7 minutes, and that the analysis of a single frame of the video took 33 ms on average. Figures 1, 2 and 3 show the metrics achieved by our network after training.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/CPU/Screenshot 2024-01-27 185829.png}
    \caption{Mean Average Precision for CPU}\label{fig:CPUmAP}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/CPU/Screenshot 2024-01-27 185928.png}
    \caption{Precision for CPU}\label{fig:CPUprecision}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/CPU/Screenshot 2024-01-27 185951.png}
    \caption{Recall for CPU}\label{fig:CPUrecall}
\end{figure}

\subsection{GPU Implementation}
The metrics of this test were slightly better than the ones generated by the CPU, on top of that we can see that the execution time for training the network was drastically reduced, taking approximately 2.6 minutes. Figures 4, 5 and 6 show the metrics obtained by our network after training.
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.35\textwidth]{Images/GPU/Screenshot 2024-01-27 182452.png}
    \caption{Mean Average Precision for GPU}\label{fig:GPUmAP}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.35\textwidth]{Images/GPU/Screenshot 2024-01-27 182658.png}
    \caption{Precision for GPU}\label{fig:GPUprecision}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.35\textwidth]{Images/GPU/Screenshot 2024-01-27 182608.png}
    \caption{Recall for GPU}\label{fig:GPUrecall}
\end{figure}

\subsubsection{Results}
When predicting the video, we got underwhelming results, shown in pictures 7, 8 and 9. Our model detects only a few people, even thought there is a crowd passing. We can also observe that the confidence of the model isn't very high, resulting from the small number of epoch during training. However the analysis of each frame takes only 15 ms, less than half of the time of the CPU.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/GPU/download (2).png}
    \caption{Network result 1}\label{NetRes1}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/GPU/download (4).png}
    \caption{Network result 2}\label{fig:NetRes2}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/GPU/download (3).png}
    \caption{Network result 3}\label{fig:NetRes3}
\end{figure}

\subsection{Infrared Training}
Alongside the regular dataset, with standard RGB video recordings, we also classified and preprocessed a similar dataset with Infrared (IR) video footage. For this implementation, knowing the CPU takes a long time to run, and performs worse, we decided to only train it on the GPU.

\subsubsection{Results}
The results obtained with with this dataset were (at least with the dataset we had) significantly better. The model was able to detect more people in the images, and had less false positives.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.4\textwidth]{Images/ir_result.png}
    \caption{IR Results}\label{fig:ir-results}
\end{figure}

\subsection{A Classical Implementation}

Machine Learning algorithms, though powerful, are no silver bullet. Depending on the scale of our problem, and the expected accuracy and results, a neural networks may just be overkill.

Looking back at our problem, we have a well controlled environment, with a fixed camera and a simple task counting people. This suggest that, maybe a classical algorithm deliver results close to the one we got with the neural network, while using less resources and running faster.

We decided to implement some simple image processing techniques to reach the same results. The approach is as follows:

\begin{itemize}
    \item Extract the background from the scene, and use it as "ground truth";
    \item Subtract our background from the image we want to process;
    \item Apply some image topology algorithms (such as opening and closing) to remove noise and refine the results;
    \item Count the "blobs" we have in the image and label the people we found in it;
\end{itemize}

\subsubsection{Background}

Processing the background is an easy test. Knowing the camera stays fixed, and the elements in the scenery do not change, it is just a matter of selecting an image with no people on them, or removing the people in one of them, assuming the are not over any background elements.

For our implementation, the image selected, and its extracted background, are below. On top of the people extracting (that in this case, was done by manually setting the rectangle containing them to zero), we also applied other image processing techniques on top, to remove noise and generate a better ground truth.

\begin{figure}[ht!]
    \centering
    \begin{minipage}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/classical/112.png}
        \caption{Extracted background}\label{fig:NetRes3}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/classical/backgroung.png}
        \caption{Extracted background}\label{fig:NetRes3}
    \end{minipage}
\end{figure}

\section{Conclusion}
Object recognition is a difficult task. The variables involved are complex to balance, and any small thing may have a huge impact in the end result. Especially in a field such as autonomous vehicles, where time and precision are crucial, this problem proves to be way harder than we first thought.

In all our implementations, we were not able to reach acceptable accuracy levels, and the timing is less than optimal for such a task, especially in the CPU training implementation. A form of graphics/AI acceleration proves indispensable for this task.

Our models, though far from perfect, do serve as an exciting first contact with this field. The results we got are promising, however we are sure that with more time, data and resources available, we could reach better numbers.

\end{document}
